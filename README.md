# Playlist_Recommendation


## Problem statement: To explore the Spotify dataset to predict the variability of the features available.

## Objectives:

1. Predict if a song is going to be popular or not.
2. Generate a playlist based on a song the listener likes.

## Solution:

Used various ML algorithms to predict the popularity of a song.

Designed a dynamic playlist generator using clustering. Using this, the user can input a track’s name and get a list of 10 similar songs. The recommended playlist would be based on the characteristics of the song which had to be normalized before the clustering process. The elbow method was used to determine the optimal number of clusters used in the k-means clustering algorithms. 12 clusters were found to be optimal. Once the song is inputted, we can investigate which of the 12 clusters it belongs to and build the playlist out of the similar songs found in that cluster.

## EXPLORATORY DATA ANALYSIS : 

Throughout my initial analysis, I decided to drop three fields from the initial dataset: unnamed: 0, track_id, and duration_ms. The unnamed column was removed as it served no purpose, being an autogenerated column unsuitable for analysis. Track_id was deemed unnecessary, as the track name field could be used in its place. Duration_ms was dropped as this variable was converted into duration_mins to make it more relevant to music-based data.

Before excluding any data, I checked how each field behaved in terms of variability by deploying a grid of histograms over all numerical fields.

For the popularity predictive model, I chose to consider data from the last 5 years (2018 to 2023), resulting in 256,766 records. For the playlist generator, all tracks before 2012 were removed to generate several clusters with a wide variety of songs.

Many values with a popularity of 0 were observed and subsequently removed, as they could hinder the model aimed at determining song popularity.

Based on the graphs in the code file, the danceability graph had very few values at 0, leading to an investigation that revealed 189 values with no danceability. Values with 0 speechiness were also examined, and it was noted that these were the same values with no danceability. These outlier values were removed from the dataset.

Genres of all songs were investigated, revealing that the songwriter column was virtually nonexistent, with only 5 values. These values were removed to avoid interference with further analysis.

After completing the necessary exploratory data analysis, which included removing songs from before 2018, songs with 0 popularity, songs with no speechiness and danceability, and the songwriter genre, the grid of histograms was updated.

The analysis proceeded by observing specific variables, such as the date of the song, artists with the most songs, the most popular track ("Flowers" by Miley Cyrus), danceability, loudness by genre, speechiness, and instrumentalness. The created variable ED_Interaction revealed that Chicago house had the highest value, a genre previously unfamiliar to the group.

## FEATURE ENGINEERING

Categorized ‘tempo’ as ‘bpm_group’ with four categories (slow, medium, fast, and rapid).
• Created a new column ‘ED_Interaction’ by multiplying ‘energy’ and ‘danceability’ since the two variables are correlated and have a similar impact on the target variable.
• Created a new column ‘IS_Ratio’ with ‘instrumentalness’ divided by ‘speechiness' since the two variables represent the balance between vocals and instrumental elements.
• Added a column named 'popular’ to categorize songs as either 'popular' or 'low' based on their popularity score (splitting on a score of 50, since a song that scores above 50 means it is in the top 10% of the popularity index)
• Added a column named ' average_acousticness’ to compute the mean acousticness for each genre within the dataframe 'df', and subsequently incorporated this data back into the original dataframe as a distinct column named 'average_acousticness'.

## MODEL DEVELOPMENT

To start the modelling process, I first defined the X and Y parameters. Since I am building a model to predict popularity, the target variable is the column ‘popularity’. For my independent variables, I chose the following columns: 'year', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_mins', 'time_signature', 'ED_Interaction', 'bpm_group', 'IS_Ratio', 'average_acousticness'.

Next, I analyzed the correlation between the target and independent columns. I concluded that danceability had the highest correlation with popularity. I hypothesized that songs with high danceability had a higher chance of being heard by a random person as they would be played in bars, dance clubs, and possibly even malls. The higher the chance of being heard most likely influenced the higher popularity. The created variable ED_Interaction had a large positive correlation with popularity whereas my other created variable, IS_Ratio, had a large negative correlation. I also used an ordinary least squares regression model, which showed promising results. This model aided in backward elimination, meaning variables where the P value was greater than 0.05 were removed. The key and time signature were removed for this reason. The r-squared value in this model was 0.582, and the RMSE value was 10.60. Next, I decided to test other regression models with the following independent variables. The categorical columns that I identified were the genre of the song, the mode, and the year. The numerical columns identified were danceability, energy, key, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration in minutes, and time signature.

The linear regression model serves as a baseline for comparing more complex algorithms. I tested out ridge, lasso, and elastic-net following linear, using the same testing and training data.

Next, I moved on to logistical regression methods, which are specifically designed to handle binary outcomes. This is the reason for the creation of the variable 'popular'. I split the data into ‘popular’ or ‘less’ to use these models. The variable 'popular' was given a value of ‘popular’ if its popularity score was greater than or equal to 50, if it was less than 50 then the variable 'popular' was given a value of ‘less’. The model's output is a probability score, which represents the likelihood of belonging to a particular class, enabling easy interpretation and decision-making.

KNN's ability to capture complex relationships between data points allows it to perform well in scenarios where the decision boundary is non-linear. Moreover, KNN is robust to noisy data and can handle outliers effectively. I also wanted to experiment with Decision Trees since they are easy to interpret and visualize, allowing users to understand the decision-making process and gain insights into feature importance. Decision Trees can handle both numerical and categorical data without the need for extensive data preprocessing. Finally, it made sense to also test Random Forest because it combines multiple decision trees to improve predictive performance and reduce overfitting. Random Forest can handle noisy data and outliers.

## MODEL EVALUATION

Popularity Prediction Model:

In testing linear models using RMSE and r-squared values, I observed that linear and ridge performed better than lasso and elastic net. However, the RMSE values were not satisfactory for proceeding with the model. I considered an r-squared value of 0.604 inadequate.

Model	                            RMSE      R-Squared Value
OLS (Ordinary Least Squares)	    10.5993  	0.582
Linear Regression	                10.3330  	0.604
Ridge Regression	                10.3330  	0.604
Lasso Regression	                15.8459  	0.070
Elastic Net	                      15.8355  	0.070

Next, I worked on logistic regression models, attempting to enhance accuracy using different solvers and increasing the maximum number of iterations. The maximum achieved accuracy was 88.65%.

Random forest initially had the highest model accuracy but consumed more time and computational power, with a higher risk of overfitting. Performing hyperparameter tuning on the decision tree model resulted in an accuracy score of 90.9%, surpassing the random forest.

Model	Accuracy
Logistic Regression	88.6%
K Nearest Neighbours	82.5%
Random Forest	90.6%
Decision Tree	90.9%
The decision tree model can be utilized to predict if a track is popular or not.

Playlist Generation Model:

Using K-means clustering based on a track name input, I generated a playlist of 10 songs. Columns like "loudness," "speechiness," etc., were normalized using the standard scaler method before clustering.

The ideal number of clusters for the K-means algorithm was determined using the elbow method, suggesting that 12 clusters would be optimal. Each cluster contains tracks with similar characteristics. Based on a specific song's cluster, playlists can be created. The dynamic input model generates a list of 10 similar songs based on the track name input.

![alt text](https://github.com/supragyabajpai/Playlist_Recommendation/blob/main/Pictures/playlist_1.jpg)
